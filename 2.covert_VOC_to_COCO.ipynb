{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "from entities import VOC2COCO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Annotation convertion from PASCAL VOC to COCO\n",
    "The annotation type used by the KAIST multispectral pedestrian dataset is not in official PASCAL VOC format. \n",
    "This makes it more difficult to convert the annotations to the YOLO format required for the YOLOV8 model.\n",
    "We first convert the annotations to COCO and subsequently convert the COCO annotations to the YOLO format. \n",
    "Because of this custom PASCAL VOC format we could not use a out-of-the-box VOC 2 YOLO converter.\n",
    "### 1. Setting the day and night source and target "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = \"B:\\\\multispectral-ped-detection\\\\data\\\\RAW\\\\kaist-cvpr15\\\\\"\n",
    "\n",
    "voc_day_annotation_paths = f'{base_path}annotations-xml-new-sanitized\\\\day\\\\**\\\\*.xml'\n",
    "voc_night_annotation_paths = f'{base_path}annotations-xml-new-sanitized\\\\night\\\\**\\\\*.xml'\n",
    "\n",
    "day_image_path = f'{base_path}images\\\\day\\\\'\n",
    "night_image_path = f'{base_path}images\\\\night\\\\'\n",
    "\n",
    "voc_day_annotations = glob.glob(voc_day_annotation_paths, recursive=True)\n",
    "voc_night_annotations = glob.glob(voc_night_annotation_paths, recursive=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "coco_day_annotations_path = \"B:/multispectral-ped-detection/data/RAW/kaist-cvpr15/annotations-coco/day.json\"\n",
    "coco_night_annotations_path = \"B:/multispectral-ped-detection/data/RAW/kaist-cvpr15/annotations-coco/night.json\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Converting to COCO\n",
    "We created a custom VOC2COCO converter based on code from this github repo:\n",
    "[https://github.com/yukkyo/voc2coco](https://github.com/yukkyo/voc2coco)\n",
    "\n",
    "We convert both day and night seperately because we want to control the ratio day/night images when splitting the dataset into train/val/test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting started\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 54542/54542 [1:07:32<00:00, 13.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved COCO annotations to B:/multispectral-ped-detection/data/RAW/kaist-cvpr15/annotations-coco/day.json.\n",
      "Converting started\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25550/25550 [20:42<00:00, 20.56it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved COCO annotations to B:/multispectral-ped-detection/data/RAW/kaist-cvpr15/annotations-coco/night.json.\n"
     ]
    }
   ],
   "source": [
    "voc2coco = VOC2COCO()\n",
    "voc2coco.convert(voc_day_annotations, coco_day_annotations_path, day_image_path)\n",
    "voc2coco.convert(voc_night_annotations, coco_night_annotations_path, night_image_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "yolo-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
